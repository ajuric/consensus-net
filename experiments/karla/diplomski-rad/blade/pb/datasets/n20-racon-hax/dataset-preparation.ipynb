{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "module_path = '/home/diplomski-rad/consensus-net/src/python/dataset/'\n",
    "if module_path not in sys.path:\n",
    "    print('Adding dataset module.')\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset with neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (1922 of 31260819) |                | Elapsed Time: 0:00:00 ETA:   0:27:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbourhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26% (8433625 of 31260819) |#     | Elapsed Time: 0:07:48 ETA:  1 day, 13:39:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbourhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% (14935299 of 31260819) |##    | Elapsed Time: 0:13:58 ETA:  1 day, 0:17:38"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbourhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74% (23380080 of 31260819) |########    | Elapsed Time: 0:22:04 ETA:  12:36:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbourhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (31260819 of 31260819) |############| Elapsed Time: 0:29:31 Time:  0:29:31\n"
     ]
    }
   ],
   "source": [
    "X_paths = [\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/e-coli-NCTC86-racon-MSA/pileups-X-0.npy',\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/m-morgani-NCTC235-racon-MSA/pileups-X-0.npy',\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/s-enterica-NCTC92-racon-MSA/pileups-X-0.npy',\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/s-enterica-NCTC129-racon-MSA/pileups-X-0.npy'\n",
    "]\n",
    "y_paths = [\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/e-coli-NCTC86-racon-MSA/pileups-y-0.npy',\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/m-morgani-NCTC235-racon-MSA/pileups-y-0.npy',\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/s-enterica-NCTC92-racon-MSA/pileups-y-0.npy',\n",
    "    '/home/diplomski-rad/blade/pb/racon-hax-pileups/s-enterica-NCTC129-racon-MSA/pileups-y-0.npy'\n",
    "]\n",
    "neighbourhood_size = 20\n",
    "save_directory_path = './'\n",
    "\n",
    "X, y = dataset.create_dataset_with_neighbourhood(neighbourhood_size, mode='training',\n",
    "    X_paths=X_paths, y_paths=y_paths)\n",
    "\n",
    "X, y = X[0], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "validation_size = 0.1\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "            X, y, test_size=validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./dataset-n20-X-train', X_train)\n",
    "np.save('./dataset-n20-X-validate', X_validate)\n",
    "np.save('./dataset-n20-y-train', y_train)\n",
    "np.save('./dataset-n20-y-validate', y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./dataset-n20-X-train.npy')\n",
    "y_train = np.load('./dataset-n20-y-train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_A = np.array([1, 0, 0, 0, 0, 0])\n",
    "class_A_indices = np.where(np.all(y_train == class_A, axis=1))[0]\n",
    "\n",
    "class_C = np.array([0, 1, 0, 0, 0, 0])\n",
    "class_C_indices = np.where(np.all(y_train == class_C, axis=1))[0]\n",
    "\n",
    "class_G = np.array([0, 0, 1, 0, 0, 0])\n",
    "class_G_indices = np.where(np.all(y_train == class_G, axis=1))[0]\n",
    "\n",
    "class_T = np.array([0, 0, 0, 1, 0, 0])\n",
    "class_T_indices = np.where(np.all(y_train == class_T, axis=1))[0]\n",
    "\n",
    "class_I = np.array([0, 0, 0, 0, 1, 0])\n",
    "class_I_indices = np.where(np.all(y_train == class_I, axis=1))[0]\n",
    "\n",
    "class_D = np.array([0, 0, 0, 0, 0, 1])\n",
    "class_D_indices = np.where(np.all(y_train == class_D, axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_A_permuted_indices = np.random.permutation(class_A_indices)\n",
    "class_C_permuted_indices = np.random.permutation(class_C_indices)\n",
    "class_G_permuted_indices = np.random.permutation(class_G_indices)\n",
    "class_T_permuted_indices = np.random.permutation(class_T_indices)\n",
    "class_I_permuted_indices = np.random.permutation(class_I_indices)\n",
    "class_D_permuted_indices = np.random.permutation(class_D_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_finetune_A = X_train[class_A_permuted_indices[:200000]]\n",
    "X_train_finetune_C = X_train[class_C_permuted_indices[:200000]]\n",
    "X_train_finetune_G = X_train[class_G_permuted_indices[:200000]]\n",
    "X_train_finetune_T = X_train[class_T_permuted_indices[:200000]]\n",
    "X_train_finetune_I = X_train[class_I_permuted_indices[:200000]]\n",
    "X_train_finetune_D = X_train[class_D_permuted_indices] # all deletions\n",
    "\n",
    "y_train_finetune_A = y_train[class_A_permuted_indices[:200000]]\n",
    "y_train_finetune_C = y_train[class_C_permuted_indices[:200000]]\n",
    "y_train_finetune_G = y_train[class_G_permuted_indices[:200000]]\n",
    "y_train_finetune_T = y_train[class_T_permuted_indices[:200000]]\n",
    "y_train_finetune_I = y_train[class_I_permuted_indices[:200000]]\n",
    "y_train_finetune_D = y_train[class_D_permuted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_finetune = np.concatenate(\n",
    "    (X_train_finetune_A, X_train_finetune_C, X_train_finetune_G, X_train_finetune_T, X_train_finetune_I, X_train_finetune_D),\n",
    "    axis=0\n",
    ")\n",
    "y_train_finetune = np.concatenate(\n",
    "    (y_train_finetune_A, y_train_finetune_C, y_train_finetune_G, y_train_finetune_T, y_train_finetune_I, y_train_finetune_D),\n",
    "    axis=0\n",
    ")\n",
    "# Permute to shuffle data.\n",
    "X_train_finetune = X_train_finetune[np.random.permutation(np.arange(X_train_finetune.shape[0]))]\n",
    "y_train_finetune = y_train_finetune[np.random.permutation(np.arange(y_train_finetune.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./dataset-n20-X-train-finetune-3.npy', X_train_finetune,)\n",
    "np.save('./dataset-n20-y-train-finetune-3.npy', y_train_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
