{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./dataset-n20-X-train-finetune.npy')\n",
    "y_train = np.load('./dataset-n20-y-train-finetune.npy')\n",
    "X_valid = np.load('./dataset-n20-X-validate.npy')\n",
    "y_valid = np.load('./dataset-n20-y-validate.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 41, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 41, 40)            640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 20, 40)            1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 40)            160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 4806      \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,286\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./model-15.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune - smaller batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 275000 samples, validate on 3109078 samples\n",
      "Epoch 1/10\n",
      "275000/275000 [==============================] - 121s 439us/step - loss: 1.8217 - acc: 0.1733 - val_loss: 1.7874 - val_acc: 0.0707\n",
      "Epoch 2/10\n",
      "275000/275000 [==============================] - 103s 375us/step - loss: 1.7940 - acc: 0.1775 - val_loss: 1.8367 - val_acc: 0.1328\n",
      "Epoch 3/10\n",
      "275000/275000 [==============================] - 102s 370us/step - loss: 1.7933 - acc: 0.1794 - val_loss: 1.8014 - val_acc: 0.1465\n",
      "Epoch 4/10\n",
      "275000/275000 [==============================] - 101s 367us/step - loss: 1.7923 - acc: 0.1791 - val_loss: 1.8034 - val_acc: 0.0206\n",
      "Epoch 5/10\n",
      "275000/275000 [==============================] - 101s 368us/step - loss: 1.7922 - acc: 0.1801 - val_loss: 1.8156 - val_acc: 0.0026\n",
      "Epoch 6/10\n",
      "275000/275000 [==============================] - 101s 369us/step - loss: 1.7920 - acc: 0.1809 - val_loss: 1.8079 - val_acc: 0.0028\n",
      "Epoch 7/10\n",
      "275000/275000 [==============================] - 102s 370us/step - loss: 1.7918 - acc: 0.1808 - val_loss: 1.7961 - val_acc: 0.0100\n",
      "Epoch 8/10\n",
      "275000/275000 [==============================] - 102s 370us/step - loss: 1.7919 - acc: 0.1809 - val_loss: 1.7942 - val_acc: 0.1198\n",
      "Epoch 9/10\n",
      "275000/275000 [==============================] - 101s 368us/step - loss: 1.7919 - acc: 0.1812 - val_loss: 1.8078 - val_acc: 0.0021\n",
      "Epoch 10/10\n",
      "275000/275000 [==============================] - 102s 371us/step - loss: 1.7921 - acc: 0.1808 - val_loss: 1.8178 - val_acc: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c2f81fbe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune - larger batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 41, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 41, 40)            640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 20, 40)            1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 40)            160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 4806      \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,286\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Train on 275000 samples, validate on 3109078 samples\n",
      "Epoch 1/10\n",
      "275000/275000 [==============================] - 14s 52us/step - loss: 2.9422 - acc: 0.1672 - val_loss: 2.2884 - val_acc: 0.1568\n",
      "Epoch 2/10\n",
      "275000/275000 [==============================] - 14s 50us/step - loss: 1.8412 - acc: 0.1716 - val_loss: 1.9027 - val_acc: 0.0570\n",
      "Epoch 3/10\n",
      "275000/275000 [==============================] - 13s 49us/step - loss: 1.8173 - acc: 0.1755 - val_loss: 1.9171 - val_acc: 0.0230\n",
      "Epoch 4/10\n",
      "275000/275000 [==============================] - 13s 48us/step - loss: 1.8121 - acc: 0.1761 - val_loss: 1.8399 - val_acc: 0.0469\n",
      "Epoch 5/10\n",
      "275000/275000 [==============================] - 13s 46us/step - loss: 1.8091 - acc: 0.1765 - val_loss: 1.8157 - val_acc: 0.0809\n",
      "Epoch 6/10\n",
      "275000/275000 [==============================] - 13s 48us/step - loss: 1.8074 - acc: 0.1781 - val_loss: 1.8383 - val_acc: 0.0619\n",
      "Epoch 7/10\n",
      "275000/275000 [==============================] - 13s 49us/step - loss: 1.8060 - acc: 0.1774 - val_loss: 1.8047 - val_acc: 0.1483\n",
      "Epoch 8/10\n",
      "275000/275000 [==============================] - 14s 49us/step - loss: 1.8048 - acc: 0.1765 - val_loss: 1.7901 - val_acc: 0.1784\n",
      "Epoch 9/10\n",
      "275000/275000 [==============================] - 13s 49us/step - loss: 1.8034 - acc: 0.1781 - val_loss: 1.8026 - val_acc: 0.1668\n",
      "Epoch 10/10\n",
      "275000/275000 [==============================] - 12s 45us/step - loss: 1.8027 - acc: 0.1778 - val_loss: 1.7828 - val_acc: 0.1964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a444d04e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model-15.h5')\n",
    "model.summary()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 10000\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune - freeze weights, larger batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 41, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 41, 40)            640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 20, 40)            1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 40)            160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 4806      \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,286\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Train on 275000 samples, validate on 3109078 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275000/275000 [==============================] - 16s 56us/step - loss: 2.9436 - acc: 0.1681 - val_loss: 2.7179 - val_acc: 0.1223\n",
      "Epoch 2/10\n",
      "275000/275000 [==============================] - 14s 50us/step - loss: 1.8460 - acc: 0.1713 - val_loss: 1.9510 - val_acc: 0.0764\n",
      "Epoch 3/10\n",
      "275000/275000 [==============================] - 13s 48us/step - loss: 1.8181 - acc: 0.1746 - val_loss: 1.8611 - val_acc: 0.0927\n",
      "Epoch 4/10\n",
      "275000/275000 [==============================] - 13s 49us/step - loss: 1.8124 - acc: 0.1751 - val_loss: 1.8764 - val_acc: 0.0476\n",
      "Epoch 5/10\n",
      "275000/275000 [==============================] - 13s 49us/step - loss: 1.8094 - acc: 0.1761 - val_loss: 1.8654 - val_acc: 0.0685\n",
      "Epoch 6/10\n",
      "275000/275000 [==============================] - 12s 44us/step - loss: 1.8073 - acc: 0.1765 - val_loss: 1.8409 - val_acc: 0.0858\n",
      "Epoch 7/10\n",
      "275000/275000 [==============================] - 13s 48us/step - loss: 1.8059 - acc: 0.1771 - val_loss: 1.8517 - val_acc: 0.0589\n",
      "Epoch 8/10\n",
      "275000/275000 [==============================] - 13s 46us/step - loss: 1.8047 - acc: 0.1771 - val_loss: 1.8509 - val_acc: 0.0311\n",
      "Epoch 9/10\n",
      "275000/275000 [==============================] - 13s 46us/step - loss: 1.8037 - acc: 0.1778 - val_loss: 1.8501 - val_acc: 0.0195\n",
      "Epoch 10/10\n",
      "275000/275000 [==============================] - 13s 46us/step - loss: 1.8028 - acc: 0.1773 - val_loss: 1.8759 - val_acc: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89ec6a6c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model-15.h5')\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "epochs = 10\n",
    "batch_size = 10000\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune - freeze weights, smaller batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 41, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 41, 40)            640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 20, 40)            1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 40)            160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 4806      \n",
      "=================================================================\n",
      "Total params: 9,846\n",
      "Trainable params: 7,286\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "Train on 275000 samples, validate on 3109078 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275000/275000 [==============================] - 20s 71us/step - loss: 1.9357 - acc: 0.1717 - val_loss: 1.8359 - val_acc: 0.1475\n",
      "Epoch 2/10\n",
      "275000/275000 [==============================] - 20s 71us/step - loss: 1.8021 - acc: 0.1752 - val_loss: 1.7911 - val_acc: 0.1740\n",
      "Epoch 3/10\n",
      "275000/275000 [==============================] - 20s 74us/step - loss: 1.7988 - acc: 0.1777 - val_loss: 1.8351 - val_acc: 0.0101\n",
      "Epoch 4/10\n",
      "275000/275000 [==============================] - 20s 73us/step - loss: 1.7973 - acc: 0.1770 - val_loss: 1.8439 - val_acc: 0.0068\n",
      "Epoch 5/10\n",
      "275000/275000 [==============================] - 20s 73us/step - loss: 1.7957 - acc: 0.1785 - val_loss: 1.7793 - val_acc: 0.1517\n",
      "Epoch 6/10\n",
      "275000/275000 [==============================] - 20s 72us/step - loss: 1.7952 - acc: 0.1770 - val_loss: 1.8313 - val_acc: 0.0545\n",
      "Epoch 7/10\n",
      "275000/275000 [==============================] - 20s 72us/step - loss: 1.7941 - acc: 0.1787 - val_loss: 1.8235 - val_acc: 0.0174\n",
      "Epoch 8/10\n",
      "275000/275000 [==============================] - 20s 72us/step - loss: 1.7937 - acc: 0.1786 - val_loss: 1.7881 - val_acc: 0.1503\n",
      "Epoch 9/10\n",
      "275000/275000 [==============================] - 20s 73us/step - loss: 1.7934 - acc: 0.1787 - val_loss: 1.8088 - val_acc: 0.0124\n",
      "Epoch 10/10\n",
      "275000/275000 [==============================] - 20s 72us/step - loss: 1.7930 - acc: 0.1795 - val_loss: 1.8127 - val_acc: 0.0360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89cc1ad470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model-15.h5')\n",
    "\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune - similar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 41, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 41, 40)            640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 20, 40)            1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 40)            160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 4806      \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,286\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Train on 275000 samples, validate on 3109078 samples\n",
      "Epoch 1/10\n",
      "275000/275000 [==============================] - 16s 57us/step - loss: 2.9708 - acc: 0.1672 - val_loss: 1.9904 - val_acc: 0.2155\n",
      "Epoch 2/10\n",
      "275000/275000 [==============================] - 14s 50us/step - loss: 1.8482 - acc: 0.1703 - val_loss: 1.6505 - val_acc: 0.3636\n",
      "Epoch 3/10\n",
      "275000/275000 [==============================] - 13s 48us/step - loss: 1.8196 - acc: 0.1738 - val_loss: 1.7811 - val_acc: 0.2325\n",
      "Epoch 4/10\n",
      "275000/275000 [==============================] - 13s 46us/step - loss: 1.8134 - acc: 0.1748 - val_loss: 1.7896 - val_acc: 0.2124\n",
      "Epoch 5/10\n",
      "275000/275000 [==============================] - 13s 46us/step - loss: 1.8097 - acc: 0.1750 - val_loss: 1.8065 - val_acc: 0.1664\n",
      "Epoch 6/10\n",
      "275000/275000 [==============================] - 12s 45us/step - loss: 1.8075 - acc: 0.1757 - val_loss: 1.7937 - val_acc: 0.1776\n",
      "Epoch 7/10\n",
      "275000/275000 [==============================] - 12s 45us/step - loss: 1.8056 - acc: 0.1762 - val_loss: 1.8378 - val_acc: 0.0408\n",
      "Epoch 8/10\n",
      "275000/275000 [==============================] - 13s 46us/step - loss: 1.8044 - acc: 0.1772 - val_loss: 1.8446 - val_acc: 0.0349\n",
      "Epoch 9/10\n",
      "275000/275000 [==============================] - 14s 50us/step - loss: 1.8033 - acc: 0.1778 - val_loss: 1.8367 - val_acc: 0.0323\n",
      "Epoch 10/10\n",
      "275000/275000 [==============================] - 13s 49us/step - loss: 1.8024 - acc: 0.1779 - val_loss: 1.8092 - val_acc: 0.0521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89969fbd68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model-15.h5')\n",
    "model.summary()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 10000\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune - similar but larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = np.load('./dataset-n20-X-train-finetune-3.npy')\n",
    "y_train_3 = np.load('./dataset-n20-y-train-finetune-3.npy')\n",
    "X_valid = np.load('./dataset-n20-X-validate.npy')\n",
    "y_valid = np.load('./dataset-n20-y-validate.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 41, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 41, 40)            640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 20, 40)            1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 40)            160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 4806      \n",
      "=================================================================\n",
      "Total params: 7,366\n",
      "Trainable params: 7,286\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Train on 1057761 samples, validate on 3109078 samples\n",
      "Epoch 1/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 2.0905 - acc: 0.1883 - val_loss: 1.7277 - val_acc: 0.2082\n",
      "Epoch 2/10\n",
      "1057761/1057761 [==============================] - 18s 17us/step - loss: 1.7504 - acc: 0.1898 - val_loss: 1.6798 - val_acc: 0.2249\n",
      "Epoch 3/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7461 - acc: 0.1903 - val_loss: 1.6721 - val_acc: 0.2978\n",
      "Epoch 4/10\n",
      "1057761/1057761 [==============================] - 18s 17us/step - loss: 1.7434 - acc: 0.1900 - val_loss: 1.6757 - val_acc: 0.2687\n",
      "Epoch 5/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7417 - acc: 0.1900 - val_loss: 1.6730 - val_acc: 0.2526\n",
      "Epoch 6/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7405 - acc: 0.1902 - val_loss: 1.6777 - val_acc: 0.2358\n",
      "Epoch 7/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7397 - acc: 0.1903 - val_loss: 1.6690 - val_acc: 0.2368\n",
      "Epoch 8/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7389 - acc: 0.1909 - val_loss: 1.6748 - val_acc: 0.3164\n",
      "Epoch 9/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7383 - acc: 0.1911 - val_loss: 1.6742 - val_acc: 0.2475\n",
      "Epoch 10/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7377 - acc: 0.1903 - val_loss: 1.6778 - val_acc: 0.2398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8995d76588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model-15.h5')\n",
    "model.summary()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 10000\n",
    "\n",
    "model.fit(X_train_3, y_train_3, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune - similar but larger dataset, frozen weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 41, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 41, 40)            640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "separable_conv1d_1 (Separabl (None, 20, 40)            1760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 40)            160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 4806      \n",
      "=================================================================\n",
      "Total params: 9,846\n",
      "Trainable params: 7,286\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "Train on 1057761 samples, validate on 3109078 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1057761/1057761 [==============================] - 20s 19us/step - loss: 2.0988 - acc: 0.1876 - val_loss: 1.6528 - val_acc: 0.3254\n",
      "Epoch 2/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7490 - acc: 0.1891 - val_loss: 1.6688 - val_acc: 0.2763\n",
      "Epoch 3/10\n",
      "1057761/1057761 [==============================] - 20s 18us/step - loss: 1.7451 - acc: 0.1892 - val_loss: 1.6561 - val_acc: 0.3396\n",
      "Epoch 4/10\n",
      "1057761/1057761 [==============================] - 20s 19us/step - loss: 1.7430 - acc: 0.1899 - val_loss: 1.6621 - val_acc: 0.2722\n",
      "Epoch 5/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7416 - acc: 0.1904 - val_loss: 1.6719 - val_acc: 0.2651\n",
      "Epoch 6/10\n",
      "1057761/1057761 [==============================] - 18s 17us/step - loss: 1.7404 - acc: 0.1905 - val_loss: 1.6652 - val_acc: 0.2923\n",
      "Epoch 7/10\n",
      "1057761/1057761 [==============================] - 18s 17us/step - loss: 1.7395 - acc: 0.1901 - val_loss: 1.6697 - val_acc: 0.2346\n",
      "Epoch 8/10\n",
      "1057761/1057761 [==============================] - 18s 17us/step - loss: 1.7388 - acc: 0.1911 - val_loss: 1.6607 - val_acc: 0.2706\n",
      "Epoch 9/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7384 - acc: 0.1904 - val_loss: 1.6662 - val_acc: 0.2617\n",
      "Epoch 10/10\n",
      "1057761/1057761 [==============================] - 19s 18us/step - loss: 1.7378 - acc: 0.1904 - val_loss: 1.6774 - val_acc: 0.1969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89954d9390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model-15.h5')\n",
    "\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 10000\n",
    "\n",
    "model.fit(X_train_3, y_train_3, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
