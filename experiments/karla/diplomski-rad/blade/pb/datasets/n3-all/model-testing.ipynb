{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset module.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "module_path = '/home/diplomski-rad/consensus-net/src/python/dataset/'\n",
    "if module_path not in sys.path:\n",
    "    print('Adding dataset module.')\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (2419 of 16691589) |                | Elapsed Time: 0:00:00 ETA:   0:11:30"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape before reshaping: (16691589, 7, 4)\n",
      "y shape before reshaping: (16691589, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16691589 of 16691589) |############| Elapsed Time: 0:08:45 Time:  0:08:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after reshaping: (16691589, 7, 1, 4)\n",
      "y shape after reshaping: (16691589, 4)\n",
      "Splitting to train and validation set.\n",
      "X_train shape: (15022430, 7, 1, 4)\n",
      "X_validate shape: (1669159, 7, 1, 4)\n",
      "y_train: (15022430, 4)\n",
      "y_validate: (1669159, 4)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_train, X_validate, y_train, y_validate = dataset.read_dataset_and_reshape_for_conv(\n",
    "    './pysam-all-dataset-n3-X.npy', './pysam-all-dataset-n3-y.npy', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./pysam-all-dataset-n3-X-reshaped', X)\n",
    "np.save('./pysam-all-dataset-n3-y-reshaped', y)\n",
    "np.save('./pysam-all-dataset-n3-X-reshaped-train', X_train)\n",
    "np.save('./pysam-all-dataset-n3-X-reshaped-validate', X_validate)\n",
    "np.save('./pysam-all-dataset-n3-y-reshaped-train', y_train)\n",
    "np.save('./pysam-all-dataset-n3-y-reshaped-validate', y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 7, 1, 4)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 1, 10)          370       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 1, 10)          40        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 1, 10)          910       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 1,604\n",
      "Trainable params: 1,584\n",
      "Non-trainable params: 20\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 15022430 samples, validate on 1669159 samples\n",
      "Epoch 1/200\n",
      "15022430/15022430 [==============================] - 40s 3us/step - loss: 0.1651 - acc: 0.9553 - val_loss: 0.0610 - val_acc: 0.9871\n",
      "Epoch 2/200\n",
      "15022430/15022430 [==============================] - 37s 2us/step - loss: 0.0688 - acc: 0.9849 - val_loss: 0.0382 - val_acc: 0.9890\n",
      "Epoch 3/200\n",
      "15022430/15022430 [==============================] - 37s 2us/step - loss: 0.0439 - acc: 0.9877 - val_loss: 0.0298 - val_acc: 0.9901\n",
      "Epoch 4/200\n",
      "15022430/15022430 [==============================] - 34s 2us/step - loss: 0.0363 - acc: 0.9889 - val_loss: 0.0256 - val_acc: 0.9914\n",
      "Epoch 5/200\n",
      "15022430/15022430 [==============================] - 33s 2us/step - loss: 0.0327 - acc: 0.9896 - val_loss: 0.0242 - val_acc: 0.9919\n",
      "Epoch 6/200\n",
      "15022430/15022430 [==============================] - 32s 2us/step - loss: 0.0308 - acc: 0.9900 - val_loss: 0.0230 - val_acc: 0.9924\n",
      "Epoch 7/200\n",
      "15022430/15022430 [==============================] - 34s 2us/step - loss: 0.0296 - acc: 0.9903 - val_loss: 0.0220 - val_acc: 0.9925\n",
      "Epoch 8/200\n",
      "15022430/15022430 [==============================] - 32s 2us/step - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0220 - val_acc: 0.9926\n",
      "Epoch 9/200\n",
      "15022430/15022430 [==============================] - 35s 2us/step - loss: 0.0284 - acc: 0.9907 - val_loss: 0.0218 - val_acc: 0.9927\n",
      "Epoch 10/200\n",
      "15022430/15022430 [==============================] - 39s 3us/step - loss: 0.0281 - acc: 0.9908 - val_loss: 0.0210 - val_acc: 0.9929\n",
      "Epoch 11/200\n",
      "15022430/15022430 [==============================] - 36s 2us/step - loss: 0.0277 - acc: 0.9909 - val_loss: 0.0208 - val_acc: 0.9932\n",
      "Epoch 12/200\n",
      "15022430/15022430 [==============================] - 35s 2us/step - loss: 0.0275 - acc: 0.9910 - val_loss: 0.0211 - val_acc: 0.9932\n",
      "Epoch 13/200\n",
      "15022430/15022430 [==============================] - 35s 2us/step - loss: 0.0274 - acc: 0.9911 - val_loss: 0.0204 - val_acc: 0.9932\n",
      "Epoch 14/200\n",
      "15022430/15022430 [==============================] - 34s 2us/step - loss: 0.0271 - acc: 0.9911 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 15/200\n",
      "15022430/15022430 [==============================] - 34s 2us/step - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0202 - val_acc: 0.9934\n",
      "Epoch 16/200\n",
      "15022430/15022430 [==============================] - 33s 2us/step - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0200 - val_acc: 0.9935\n",
      "Epoch 17/200\n",
      "15022430/15022430 [==============================] - 32s 2us/step - loss: 0.0268 - acc: 0.9912 - val_loss: 0.0199 - val_acc: 0.9934\n",
      "Epoch 18/200\n",
      "15022430/15022430 [==============================] - 36s 2us/step - loss: 0.0269 - acc: 0.9912 - val_loss: 0.0201 - val_acc: 0.9935\n",
      "Epoch 19/200\n",
      " 4820000/15022430 [========>.....................] - ETA: 24s - loss: 0.0267 - acc: 0.9912"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(7, 1, 4))\n",
    "conv_1 = Conv2D(filters=10, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "bn_1 = BatchNormalization()(conv_1)\n",
    "conv_2 = Conv2D(filters=10, kernel_size=3, padding='same', activation='relu')(bn_1)\n",
    "drop_1 = Dropout(0.25)(conv_2)\n",
    "\n",
    "flatten = Flatten()(drop_1)\n",
    "predictions = Dense(4, activation='softmax')(flatten)\n",
    "\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 200\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
