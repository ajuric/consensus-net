{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding dataset module.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "module_path = '/home/diplomski-rad/consensus-net/src/python/dataset/'\n",
    "if module_path not in sys.path:\n",
    "    print('Adding dataset module.')\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create neighbourhood from reads-to-ref pileups for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing  /home/diplomski-rad/blade/pileups/e-coli-NCTC86-pysam-X-dataset.npy  and  /home/diplomski-rad/blade/pileups/e-coli-NCTC86-pysam-y-dataset.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (4186 of 4641652) |                 | Elapsed Time: 0:00:00 ETA:   0:03:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbrouhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4641652 of 4641652) |##############| Elapsed Time: 0:03:34 Time:  0:03:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing  /home/diplomski-rad/blade/pileups/m-morgani-NCTC235-pysam-X-dataset.npy  and  /home/diplomski-rad/blade/pileups/m-morgani-NCTC235-pysam-y-dataset.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (4187 of 3799539) |                 | Elapsed Time: 0:00:00 ETA:   0:03:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbrouhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3799539 of 3799539) |##############| Elapsed Time: 0:02:52 Time:  0:02:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing  /home/diplomski-rad/blade/pileups/s-enterica-NCTC92-pysam-X-dataset.npy  and  /home/diplomski-rad/blade/pileups/s-enterica-NCTC92-pysam-y-dataset.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (4186 of 4809037) |                 | Elapsed Time: 0:00:00 ETA:   0:03:49"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbrouhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4809037 of 4809037) |##############| Elapsed Time: 0:03:30 Time:  0:03:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing  /home/diplomski-rad/blade/pileups/s-enterica-NXTC129-pysam-X-dataset.npy  and  /home/diplomski-rad/blade/pileups/s-enterica-NXTC129-pysam-y-dataset.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (4203 of 4809037) |                 | Elapsed Time: 0:00:00 ETA:   0:03:48"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with neighbrouhood ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4809037 of 4809037) |##############| Elapsed Time: 0:03:44 Time:  0:03:44\n"
     ]
    }
   ],
   "source": [
    "X_paths = ['/home/diplomski-rad/blade/pileups/e-coli-NCTC86-pysam-X-dataset.npy',\n",
    "           '/home/diplomski-rad/blade/pileups/m-morgani-NCTC235-pysam-X-dataset.npy',\n",
    "           '/home/diplomski-rad/blade/pileups/s-enterica-NCTC92-pysam-X-dataset.npy',\n",
    "           '/home/diplomski-rad/blade/pileups/s-enterica-NXTC129-pysam-X-dataset.npy']\n",
    "y_paths = ['/home/diplomski-rad/blade/pileups/e-coli-NCTC86-pysam-y-dataset.npy',\n",
    "           '/home/diplomski-rad/blade/pileups/m-morgani-NCTC235-pysam-y-dataset.npy',\n",
    "           '/home/diplomski-rad/blade/pileups/s-enterica-NCTC92-pysam-y-dataset.npy',\n",
    "           '/home/diplomski-rad/blade/pileups/s-enterica-NXTC129-pysam-y-dataset.npy']\n",
    "neighbourhood_size = 10\n",
    "\n",
    "X, y = dataset.create_dataset_with_neighbourhood(X_paths, y_paths, neighbourhood_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./pysam-all-dataset-n10-X.npy', X)\n",
    "np.save('./pysam-all-dataset-n10-y.npy', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (6091 of 16668390) |                | Elapsed Time: 0:00:00 ETA:   0:09:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape before reshaping: (16668390, 21, 4)\n",
      "y shape before reshaping: (16668390, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16668390 of 16668390) |############| Elapsed Time: 0:11:21 Time:  0:11:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after reshaping: (16668390, 21, 1, 4)\n",
      "y shape after reshaping: (16668390, 4)\n",
      "Splitting to train and validation set.\n",
      "X_train shape: (15001551, 21, 1, 4)\n",
      "X_validate shape: (1666839, 21, 1, 4)\n",
      "y_train: (15001551, 4)\n",
      "y_validate: (1666839, 4)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_train, X_validate, y_train, y_validate = dataset.read_dataset_and_reshape_for_conv(\n",
    "    './pysam-all-dataset-n10-X.npy', './pysam-all-dataset-n10-y.npy', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./pysam-all-dataset-n10-X-reshaped', X)\n",
    "np.save('./pysam-all-dataset-n10-y-reshaped', y)\n",
    "np.save('./pysam-all-dataset-n10-X-reshaped-train', X_train)\n",
    "np.save('./pysam-all-dataset-n10-X-reshaped-validate', X_validate)\n",
    "np.save('./pysam-all-dataset-n10-y-reshaped-train', y_train)\n",
    "np.save('./pysam-all-dataset-n10-y-reshaped-validate', y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 21, 1, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 21, 1, 20)         740       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 21, 1, 20)         3620      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 420)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 1684      \n",
      "=================================================================\n",
      "Total params: 6,044\n",
      "Trainable params: 6,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 15001551 samples, validate on 1666839 samples\n",
      "Epoch 1/20\n",
      "15001551/15001551 [==============================] - 58s 4us/step - loss: 0.1207 - acc: 0.9769 - val_loss: 0.0354 - val_acc: 0.9910\n",
      "Epoch 2/20\n",
      "15001551/15001551 [==============================] - 59s 4us/step - loss: 0.0291 - acc: 0.9921 - val_loss: 0.0256 - val_acc: 0.9928\n",
      "Epoch 3/20\n",
      " 3540000/15001551 [======>.......................] - ETA: 47s - loss: 0.0237 - acc: 0.9931"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-cbc1ddab59b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1222\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(21, 1, 4))\n",
    "conv_1 = Conv2D(filters=20, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "conv_2 = Conv2D(filters=20, kernel_size=3, padding='same', activation='relu')(conv_1)\n",
    "\n",
    "flatten = Flatten()(conv_2)\n",
    "predictions = Dense(4, activation='softmax')(flatten)\n",
    "\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 21, 1, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 21, 1, 20)         740       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 1, 20)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 1, 20)         3620      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 5,164\n",
      "Trainable params: 5,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 15001551 samples, validate on 1666839 samples\n",
      "Epoch 1/20\n",
      "15001551/15001551 [==============================] - 55s 4us/step - loss: 0.1576 - acc: 0.9660 - val_loss: 0.0549 - val_acc: 0.9886\n",
      "Epoch 2/20\n",
      "15001551/15001551 [==============================] - 48s 3us/step - loss: 0.0448 - acc: 0.9899 - val_loss: 0.0383 - val_acc: 0.9908\n",
      "Epoch 3/20\n",
      "15001551/15001551 [==============================] - 42s 3us/step - loss: 0.0350 - acc: 0.9912 - val_loss: 0.0326 - val_acc: 0.9917\n",
      "Epoch 4/20\n",
      "15001551/15001551 [==============================] - 40s 3us/step - loss: 0.0282 - acc: 0.9924 - val_loss: 0.0263 - val_acc: 0.9927\n",
      "Epoch 5/20\n",
      "15001551/15001551 [==============================] - 39s 3us/step - loss: 0.0227 - acc: 0.9936 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "Epoch 6/20\n",
      "15001551/15001551 [==============================] - 40s 3us/step - loss: 0.0202 - acc: 0.9942 - val_loss: 0.0197 - val_acc: 0.9942\n",
      "Epoch 7/20\n",
      "15001551/15001551 [==============================] - 38s 3us/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0198 - val_acc: 0.9942\n",
      "Epoch 8/20\n",
      "15001551/15001551 [==============================] - 40s 3us/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0189 - val_acc: 0.9944\n",
      "Epoch 9/20\n",
      "15001551/15001551 [==============================] - 38s 3us/step - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0180 - val_acc: 0.9947\n",
      "Epoch 10/20\n",
      "15001551/15001551 [==============================] - 40s 3us/step - loss: 0.0175 - acc: 0.9948 - val_loss: 0.0179 - val_acc: 0.9947\n",
      "Epoch 11/20\n",
      "15001551/15001551 [==============================] - 39s 3us/step - loss: 0.0171 - acc: 0.9949 - val_loss: 0.0171 - val_acc: 0.9949\n",
      "Epoch 12/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.0169 - val_acc: 0.9949\n",
      "Epoch 13/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0165 - acc: 0.9951 - val_loss: 0.0169 - val_acc: 0.9950\n",
      "Epoch 14/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0162 - acc: 0.9952 - val_loss: 0.0164 - val_acc: 0.9951\n",
      "Epoch 15/20\n",
      "15001551/15001551 [==============================] - 45s 3us/step - loss: 0.0157 - acc: 0.9953 - val_loss: 0.0175 - val_acc: 0.9949\n",
      "Epoch 16/20\n",
      "15001551/15001551 [==============================] - 41s 3us/step - loss: 0.0154 - acc: 0.9953 - val_loss: 0.0156 - val_acc: 0.9953\n",
      "Epoch 17/20\n",
      "15001551/15001551 [==============================] - 39s 3us/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0153 - val_acc: 0.9953\n",
      "Epoch 18/20\n",
      "15001551/15001551 [==============================] - 39s 3us/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0149 - val_acc: 0.9954\n",
      "Epoch 19/20\n",
      "15001551/15001551 [==============================] - 39s 3us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 0.0151 - val_acc: 0.9954\n",
      "Epoch 20/20\n",
      "15001551/15001551 [==============================] - 39s 3us/step - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0151 - val_acc: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13080bb2b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(21, 1, 4))\n",
    "conv_1 = Conv2D(filters=20, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 1))(conv_1)\n",
    "conv_2 = Conv2D(filters=20, kernel_size=3, padding='same', activation='relu')(pool_1)\n",
    "\n",
    "flatten = Flatten()(conv_2)\n",
    "predictions = Dense(4, activation='softmax')(flatten)\n",
    "\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model-conv_pool_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 21, 1, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 21, 1, 40)         1480      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 1, 40)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 10, 1, 20)         7220      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 9,504\n",
      "Trainable params: 9,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 15001551 samples, validate on 1666839 samples\n",
      "Epoch 1/20\n",
      "15001551/15001551 [==============================] - 54s 4us/step - loss: 0.1350 - acc: 0.9722 - val_loss: 0.0565 - val_acc: 0.9887\n",
      "Epoch 2/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0449 - acc: 0.9898 - val_loss: 0.0339 - val_acc: 0.9912\n",
      "Epoch 3/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0287 - acc: 0.9924 - val_loss: 0.0253 - val_acc: 0.9932\n",
      "Epoch 4/20\n",
      "15001551/15001551 [==============================] - 50s 3us/step - loss: 0.0230 - acc: 0.9937 - val_loss: 0.0213 - val_acc: 0.9941\n",
      "Epoch 5/20\n",
      "15001551/15001551 [==============================] - 52s 3us/step - loss: 0.0202 - acc: 0.9943 - val_loss: 0.0191 - val_acc: 0.9945\n",
      "Epoch 6/20\n",
      "15001551/15001551 [==============================] - 63s 4us/step - loss: 0.0185 - acc: 0.9947 - val_loss: 0.0184 - val_acc: 0.9948\n",
      "Epoch 7/20\n",
      "15001551/15001551 [==============================] - 52s 3us/step - loss: 0.0171 - acc: 0.9951 - val_loss: 0.0168 - val_acc: 0.9953\n",
      "Epoch 8/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0162 - acc: 0.9953 - val_loss: 0.0160 - val_acc: 0.9954\n",
      "Epoch 9/20\n",
      "15001551/15001551 [==============================] - 50s 3us/step - loss: 0.0154 - acc: 0.9955 - val_loss: 0.0156 - val_acc: 0.9955\n",
      "Epoch 10/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.0153 - val_acc: 0.9955\n",
      "Epoch 11/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0144 - acc: 0.9958 - val_loss: 0.0148 - val_acc: 0.9957\n",
      "Epoch 12/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.0142 - val_acc: 0.9958\n",
      "Epoch 13/20\n",
      "15001551/15001551 [==============================] - 50s 3us/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.0138 - val_acc: 0.9960\n",
      "Epoch 14/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0124 - val_acc: 0.9963\n",
      "Epoch 15/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0122 - val_acc: 0.9963\n",
      "Epoch 16/20\n",
      "15001551/15001551 [==============================] - 50s 3us/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0122 - val_acc: 0.9963\n",
      "Epoch 17/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0120 - val_acc: 0.9964\n",
      "Epoch 18/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0118 - val_acc: 0.9965\n",
      "Epoch 19/20\n",
      "15001551/15001551 [==============================] - 50s 3us/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.0113 - val_acc: 0.9966\n",
      "Epoch 20/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0109 - val_acc: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f134867fe10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape=(21, 1, 4))\n",
    "conv_1 = Conv2D(filters=40, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 1))(conv_1)\n",
    "conv_2 = Conv2D(filters=20, kernel_size=3, padding='same', activation='relu')(pool_1)\n",
    "\n",
    "flatten = Flatten()(conv_2)\n",
    "predictions = Dense(4, activation='softmax')(flatten)\n",
    "\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model-conv40_pool_conv20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15001551 samples, validate on 1666839 samples\n",
      "Epoch 1/20\n",
      "15001551/15001551 [==============================] - 53s 4us/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0111 - val_acc: 0.9967\n",
      "Epoch 2/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.0107 - val_acc: 0.9968\n",
      "Epoch 3/20\n",
      "15001551/15001551 [==============================] - 48s 3us/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0110 - val_acc: 0.9967\n",
      "Epoch 4/20\n",
      "15001551/15001551 [==============================] - 57s 4us/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0107 - val_acc: 0.9968\n",
      "Epoch 5/20\n",
      "15001551/15001551 [==============================] - 61s 4us/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0126 - val_acc: 0.9963\n",
      "Epoch 6/20\n",
      "15001551/15001551 [==============================] - 64s 4us/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0100 - val_acc: 0.9970\n",
      "Epoch 7/20\n",
      "15001551/15001551 [==============================] - 62s 4us/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.0106 - val_acc: 0.9968\n",
      "Epoch 8/20\n",
      "15001551/15001551 [==============================] - 54s 4us/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.0099 - val_acc: 0.9970\n",
      "Epoch 9/20\n",
      "15001551/15001551 [==============================] - 51s 3us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0108 - val_acc: 0.9968\n",
      "Epoch 10/20\n",
      "15001551/15001551 [==============================] - 48s 3us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.0099 - val_acc: 0.9970\n",
      "Epoch 11/20\n",
      "15001551/15001551 [==============================] - 48s 3us/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0099 - val_acc: 0.9970\n",
      "Epoch 12/20\n",
      "15001551/15001551 [==============================] - 48s 3us/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0100 - val_acc: 0.9970\n",
      "Epoch 13/20\n",
      "15001551/15001551 [==============================] - 47s 3us/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 14/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0096 - val_acc: 0.9971\n",
      "Epoch 15/20\n",
      "15001551/15001551 [==============================] - 48s 3us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0095 - val_acc: 0.9971\n",
      "Epoch 16/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 17/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0090 - acc: 0.9973 - val_loss: 0.0099 - val_acc: 0.9971\n",
      "Epoch 18/20\n",
      "15001551/15001551 [==============================] - 49s 3us/step - loss: 0.0090 - acc: 0.9973 - val_loss: 0.0093 - val_acc: 0.9972\n",
      "Epoch 19/20\n",
      "15001551/15001551 [==============================] - 47s 3us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0097 - val_acc: 0.9971\n",
      "Epoch 20/20\n",
      "15001551/15001551 [==============================] - 48s 3us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0094 - val_acc: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13407f1f60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 5 == 0:\n",
    "        return lr * 0.95\n",
    "    return lr\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "callbacks = [lr_callback]\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model-conv40_pool_conv20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
