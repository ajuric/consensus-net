{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from comet_ml import Experiment\n",
    "\n",
    "# experiment = Experiment(api_key=\"oda8KKpxlDgWmJG5KsYrrhmIV\", project_name=\"consensusnet\")\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sequence generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import Sequence\n",
    "\n",
    "\n",
    "class PileupSequence(Sequence):\n",
    "    \"\"\"\n",
    "    Class for creating batches while training.\n",
    "\n",
    "    Instance of this class is provided in fit_generator() method for training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_paths, classes, batch_size, num_classes):\n",
    "        \"\"\"\n",
    "        :param X_paths: list of paths to data\n",
    "        :type X_paths: list of str\n",
    "        :param classes: labels for data\n",
    "        :type classes: np.ndarray\n",
    "        :param batch_size: size of training batch\n",
    "        :type batch_size: int\n",
    "        :param num_classes: number of labels classes\n",
    "        :type num_classes: int\n",
    "        \"\"\"\n",
    "        if not len(X_paths) == len(classes):\n",
    "            raise ValueError('You must provide same number of Xs and ys! '\n",
    "                             'Number of Xs given is {], and number of ys '\n",
    "                             'given is {}'.format(len(X_paths), len(classes)))\n",
    "        if batch_size < 1 or batch_size > len(X_paths):\n",
    "            raise ValueError('Batch size must be positive number less than '\n",
    "                             'number of Xs, but {} given.'.format(batch_size))\n",
    "\n",
    "        self.X_paths, self.classes = X_paths, classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.X_paths[\n",
    "                  idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.classes[\n",
    "                  idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([np.load(file_name) for file_name in batch_x]), \\\n",
    "            _to_categorical(batch_y, num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "def _to_categorical(y, num_classes=None):\n",
    "    \"\"\"\n",
    "    Converts given labels to one-hot encoding (i.e. categorical).\n",
    "\n",
    "    :param y:\n",
    "    :type y: np.ndarray\n",
    "    :param num_classes:\n",
    "    :type num_classes: int\n",
    "    :return: Labels one-hot encoded.\n",
    "    :rtype: np.ndarray\n",
    "    \"\"\"\n",
    "    if num_classes < 1:\n",
    "        raise ValueError('Number of classes must be positive int, but {} '\n",
    "                         'given.'.format(num_classes))\n",
    "    if not len(y.shape) == 1:\n",
    "        raise ValueError('y must be 1-D numpy array, but {} shape '\n",
    "                         'given.'.format(y.shape))\n",
    "\n",
    "    n = y.shape[0]\n",
    "\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(y)\n",
    "\n",
    "    categorical = np.zeros((n, num_classes), dtype=np.uint8)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "classes = np.load('./dataset-classes-y.npy')\n",
    "X_paths = [os.path.join('./X/', xi) for xi in os.listdir('./X/')]\n",
    "batch_size = 1\n",
    "num_classes = 4\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 21, 1, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 21, 1, 16)         880       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 21, 1, 32)         4640      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1042)              701266    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1042)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 4172      \n",
      "=================================================================\n",
      "Total params: 710,958\n",
      "Trainable params: 710,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "   110/169536 [..............................] - ETA: 37:17:21 - loss: 6.6072 - acc: 0.2555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-67:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Process ForkPoolWorker-69:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-576b88060c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "Process ForkPoolWorker-66:\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-64:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "Process ForkPoolWorker-61:\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-65:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Process ForkPoolWorker-60:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-63:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Process ForkPoolWorker-68:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-62:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-58:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in __getitem__\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "  File \"<ipython-input-2-f8c5d0676194>\", line 44, in <listcomp>\n",
      "    return np.array([np.load(file_name) for file_name in batch_x]),             _to_categorical(batch_y, num_classes=self.num_classes)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\", line 404, in load\n",
      "    magic = fid.read(N)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "generator = PileupSequence(X_paths, classes, batch_size, num_classes)\n",
    "\n",
    "example_shape = (21, 1, 6)\n",
    "input_layer = Input(shape=example_shape)\n",
    "\n",
    "conv_1 = Conv2D(filters=16, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "conv_2 = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')(conv_1)\n",
    "\n",
    "flatten = Flatten()(conv_2)\n",
    "dense_1 = Dense(1042)(flatten)\n",
    "dropout_1 = Dropout(0.25)(dense_1)\n",
    "predictions = Dense(4, activation='softmax')(dropout_1)\n",
    "\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# batch_size = 10000\n",
    "epochs = 3\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))\n",
    "model.fit_generator(generator, epochs=epochs, use_multiprocessing=True, workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./dataset-n10-X-reshaped-train.npy')\n",
    "X_validate = np.load('./dataset-n10-X-reshaped-validate.npy')\n",
    "y_train = np.load('./dataset-n10-y-reshaped-train.npy')\n",
    "y_validate = np.load('./dataset-n10-y-reshaped-validate.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 21, 1, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 21, 1, 5)          275       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 21, 1, 5)          230       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 105)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1060      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 1,609\n",
      "Trainable params: 1,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 15258174 samples, validate on 1695353 samples\n",
      "Epoch 1/5\n",
      "15258174/15258174 [==============================] - 63s 4us/step - loss: 1.7456 - acc: 0.4967 - val_loss: 0.3852 - val_acc: 0.8596\n",
      "Epoch 2/5\n",
      "15258174/15258174 [==============================] - 63s 4us/step - loss: 0.2154 - acc: 0.9283 - val_loss: 0.0977 - val_acc: 0.9744\n",
      "Epoch 3/5\n",
      "15258174/15258174 [==============================] - 66s 4us/step - loss: 0.1168 - acc: 0.9698 - val_loss: 0.0896 - val_acc: 0.9751\n",
      "Epoch 4/5\n",
      "15258174/15258174 [==============================] - 65s 4us/step - loss: 0.1041 - acc: 0.9733 - val_loss: 0.0853 - val_acc: 0.9757\n",
      "Epoch 5/5\n",
      "15258174/15258174 [==============================] - 66s 4us/step - loss: 0.0989 - acc: 0.9746 - val_loss: 0.0831 - val_acc: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4433e36a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_shape = X_train.shape[1:]\n",
    "input_layer = Input(shape=example_shape)\n",
    "\n",
    "conv_1 = Conv2D(filters=5, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "conv_2 = Conv2D(filters=5, kernel_size=3, padding='same', activation='relu')(conv_1)\n",
    "\n",
    "flatten = Flatten()(conv_2)\n",
    "dense_1 = Dense(10)(flatten)\n",
    "dropout_1 = Dropout(0.25)(dense_1)\n",
    "predictions = Dense(4, activation='softmax')(dropout_1)\n",
    "\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "batch_size = 50000\n",
    "epochs = 5\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model-slim.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15258174 samples, validate on 1695353 samples\n",
      "Epoch 1/5\n",
      "15258174/15258174 [==============================] - 72s 5us/step - loss: 0.0947 - acc: 0.9753 - val_loss: 0.0797 - val_acc: 0.9767\n",
      "Epoch 2/5\n",
      "15258174/15258174 [==============================] - 64s 4us/step - loss: 0.0893 - acc: 0.9760 - val_loss: 0.0743 - val_acc: 0.9775\n",
      "Epoch 3/5\n",
      "15258174/15258174 [==============================] - 64s 4us/step - loss: 0.0828 - acc: 0.9769 - val_loss: 0.0692 - val_acc: 0.9783\n",
      "Epoch 4/5\n",
      "15258174/15258174 [==============================] - 67s 4us/step - loss: 0.0766 - acc: 0.9776 - val_loss: 0.0648 - val_acc: 0.9789\n",
      "Epoch 5/5\n",
      "15258174/15258174 [==============================] - 62s 4us/step - loss: 0.0731 - acc: 0.9779 - val_loss: 0.0634 - val_acc: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2cfa706ef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./model-slim.h5')\n",
    "\n",
    "batch_size = 50000\n",
    "epochs = 5\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15258174 samples, validate on 1695353 samples\n",
      "Epoch 1/5\n",
      "15258174/15258174 [==============================] - 61s 4us/step - loss: 0.0710 - acc: 0.9780 - val_loss: 0.0619 - val_acc: 0.9793\n",
      "Epoch 2/5\n",
      "15258174/15258174 [==============================] - 65s 4us/step - loss: 0.0697 - acc: 0.9782 - val_loss: 0.0611 - val_acc: 0.9796\n",
      "Epoch 3/5\n",
      "15258174/15258174 [==============================] - 65s 4us/step - loss: 0.0684 - acc: 0.9784 - val_loss: 0.0601 - val_acc: 0.9797\n",
      "Epoch 4/5\n",
      "15258174/15258174 [==============================] - 65s 4us/step - loss: 0.0672 - acc: 0.9786 - val_loss: 0.0594 - val_acc: 0.9798\n",
      "Epoch 5/5\n",
      "15258174/15258174 [==============================] - 64s 4us/step - loss: 0.0666 - acc: 0.9787 - val_loss: 0.0599 - val_acc: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ca855a710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50000\n",
    "epochs = 5\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15258174 samples, validate on 1695353 samples\n",
      "Epoch 1/5\n",
      "15258174/15258174 [==============================] - 60s 4us/step - loss: 0.0661 - acc: 0.9787 - val_loss: 0.0590 - val_acc: 0.9800\n",
      "Epoch 2/5\n",
      "15258174/15258174 [==============================] - 62s 4us/step - loss: 0.0656 - acc: 0.9788 - val_loss: 0.0582 - val_acc: 0.9796\n",
      "Epoch 3/5\n",
      "15258174/15258174 [==============================] - 64s 4us/step - loss: 0.0649 - acc: 0.9789 - val_loss: 0.0579 - val_acc: 0.9803\n",
      "Epoch 4/5\n",
      "15258174/15258174 [==============================] - 58s 4us/step - loss: 0.0642 - acc: 0.9789 - val_loss: 0.0576 - val_acc: 0.9794\n",
      "Epoch 5/5\n",
      "15258174/15258174 [==============================] - 61s 4us/step - loss: 0.0636 - acc: 0.9790 - val_loss: 0.0568 - val_acc: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31ca786b38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50000\n",
    "epochs = 5\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15258174 samples, validate on 1695353 samples\n",
      "Epoch 1/5\n",
      "15258174/15258174 [==============================] - 57s 4us/step - loss: 0.0635 - acc: 0.9791 - val_loss: 0.0569 - val_acc: 0.9799\n",
      "Epoch 2/5\n",
      "15258174/15258174 [==============================] - 57s 4us/step - loss: 0.0632 - acc: 0.9792 - val_loss: 0.0567 - val_acc: 0.9805\n",
      "Epoch 3/5\n",
      "15258174/15258174 [==============================] - 56s 4us/step - loss: 0.0630 - acc: 0.9792 - val_loss: 0.0563 - val_acc: 0.9803\n",
      "Epoch 4/5\n",
      "15258174/15258174 [==============================] - 58s 4us/step - loss: 0.0629 - acc: 0.9792 - val_loss: 0.0581 - val_acc: 0.9803\n",
      "Epoch 5/5\n",
      "15258174/15258174 [==============================] - 57s 4us/step - loss: 0.0628 - acc: 0.9792 - val_loss: 0.0561 - val_acc: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f311572b0f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50000\n",
    "epochs = 5\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model-slim-better.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
