{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: We detected that you are running inside a Ipython/Jupyter notebook environment but we cannot save your notebook source code. Please be sure to have installed comet_ml as a notebook server extension by running:\n",
      "jupyter comet_ml enable \n",
      "For more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors\n",
      "COMET WARNING: Comet.ml support for Ipython Notebook is limited at the moment, automatic monitoring and stdout capturing is deactivated \n",
      "For more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/ajuric/consensusnet/c19ac46c435c4fb3a62c507cb741dda2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(api_key=\"oda8KKpxlDgWmJG5KsYrrhmIV\", project_name=\"consensusnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajuric/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Input, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPool2D\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3109078, 41, 5)\n",
      "(3109078, 6)\n"
     ]
    }
   ],
   "source": [
    "X_validate, y_validate = np.load('./dataset-n20-X-validate.npy'), np.load('./dataset-n20-y-validate.npy')\n",
    "print(X_validate.shape)\n",
    "print(y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 50:\n",
    "        if epoch % 10 == 0:\n",
    "            return lr * 0.95\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "callbacks = [lr_callback, \n",
    "             EarlyStopping(monitor='loss', patience=3),]\n",
    "#              TensorBoard(log_dir=tensorboard_output_dir, write_images=True, write_grads=True, histogram_freq=5, batch_size=10000)]\n",
    "\n",
    "input_shape = X_validate.shape[1:]\n",
    "num_output_classes = y_validate.shape[1]\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "conv_1 = Conv1D(filters=16, kernel_size=4, padding='same', activation='selu', kernel_regularizer=l2(1e-3))(input_layer)\n",
    "pool_1 = MaxPooling1D(pool_size=(5), strides=1)(conv_1)\n",
    "\n",
    "conv_2 = Conv1D(filters=32, kernel_size=4, padding='same', activation='selu', kernel_regularizer=l2(1e-3))(pool_1)\n",
    "pool_2 = MaxPooling1D(pool_size=(4), strides=1)(conv_2)\n",
    "\n",
    "conv_3 = Conv1D(filters=48, kernel_size=4, padding='same', activation='selu', kernel_regularizer=l2(1e-3))(pool_2)\n",
    "pool_3 = MaxPooling1D(pool_size=(3), strides=1)(conv_3)\n",
    "\n",
    "flatten = Flatten()(pool_3)\n",
    "\n",
    "dn_1 = Dense(336, activation='selu')(flatten)\n",
    "drop = Dropout(0.5)(dn_1)\n",
    "\n",
    "predictions = Dense(num_output_classes, activation='softmax')(drop)\n",
    "\n",
    "model = Model(input_layer, predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 150"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
